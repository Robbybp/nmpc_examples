\documentclass{article}

\setcounter{secnumdepth}{0}
\setlength{\parindent}{0pt}

\newcommand{\RP}{\vspace{0.5cm}RP\vspace{0.2cm}\hrule\vspace{0.2cm}}

\title{Implementing data structures for dynamic optimization and examples}

\begin{document}
\maketitle

\section{August 3, 2022}

Data structure for interval data.
Have a \texttt{series\_to\_interval} function.
Before testing this data structure in \texttt{pipeline-examples} branch
and \texttt{gas\_distribution} repo, I need the ability to load data
from IntervalData.

\medskip

Have the code to convert series to interval and load interval data.
Now I need to test.
\begin{itemize}
  \item Refactor current tests to use new data structures.
  \item Use in \texttt{pipeline-examples} branch
  \item Use in \texttt{gas\_distribution} repo (some new branch, probably)
\end{itemize}

\section{August 2, 2022}

Data structure for interval data.
This is used all the time when setting a target demand sequence.
Or a piecewise-constant setpoint, presumably
\begin{itemize}
  \item Maps cuids to lists of values.
  \item The time list is now an interval list.
    List of (low, high) tuples.
  \item Construct from (data, interval list).
    Or from TimeSeriesData?
  \item Should probably just have helper functions to convert between
    series data and interval data.
  \item Then loading into model can happen via \texttt{load\_data}.
\end{itemize}
Since this is so important, I should probably update all the gas distribution
NMPC code to use a new IntervalData data structure.

\section{August 1, 2022}

Update pipeline open loop and NMPC examples to import data structures
and interfaces from Pyomo.

\section{June 1, 2022}

Kuan-Han's MHE example appears to work fine using my data structures
and utility functions wherever they make sense (to me).
Now I would like to add some additional useful functionality.
\begin{itemize}
  \item Data structure for scalar data associated with time-indexed variables.
  \item Method to get the list of data points associated with a particular
    variable. Like a \texttt{getitem}, but that processes the key to convert
    it to ``time-indexed CUID.''
  \item Maybe some functions for adding noise to data.
\end{itemize}

\section{Mar 17, 2022}

Where did the code in the \texttt{simple\_pipeline} directory go?

\section{Feb 14, 2022}

Updating names, etc.:
\begin{itemize}
  \item \texttt{get\_scalar\_data} $\rightarrow$
    \texttt{get\_scalar\_variable\_data}
  \item \texttt{propagate\_values} has been replaced with the more
    general \texttt{copy\_values\_at\_time} method.
    Default behavior is to copy from the first time point to every
    time point.
  \item \texttt{shift\_values} $\rightarrow$
    \texttt{shift\_values\_by\_time}
  \item Added \texttt{get\_data\_at\_time\_indices} method to data class
  \item Update \texttt{get\_data\_at\_time} in the data class to accept
    an iterable of time points to match the API of \texttt{get\_data\_at\_time}
    in the helper class.
  \item Names of \texttt{shift\_time\_points} and
    \texttt{project\_onto\_variables} are unchanged for now.
    \begin{itemize}
      \item Now I've changed \texttt{project\_onto\_variables} to
	\texttt{extract\_variables} and changed the API to return a new
	TimeSeriesData object
    \end{itemize}
\end{itemize}

\section{Feb 9, 2022}

More problems with names:
\begin{itemize}
  \item \texttt{load\_data\_at\_time} should specify that we are only
    loading scalar data (but it should be made clear that we can load
    this data into multiple points in time)
  \item Method for shifting time points should probably have the same
    name between time series data object and dynamic model helper.
    \begin{itemize}
      \item Now (2/14) I disagree.
      \item We are doing different things in these two functions, so they
	should have different names
      \item In the data class, we are basicall shifting the time points
	in place. There are no bounds of a continuous set we must
	respect.
      \item In the helper class, we shift values of variables within an
	existing continuous set. If a time point is outside of the set,
	we have some special handling that is not present in the data class
	method.
    \end{itemize}
\end{itemize}

Other areas for improvement/discussion with these data structures:
\begin{itemize}
  \item Is a ``propagate values'' function really necessary when we
    have ``shift values by time''?
  \item A class for scalar data seems like it would be useful, if only to
    process user-provided keys, e.g. when we send weight data to
    the tracking cost expression function.
\end{itemize}

\section{Feb 8, 2022}

My immediate priority is to rename some methods.
Another question is whether a pure dictionary is an acceptable
data type for ``scalar\_data''

What problems would I like to resolve:
\begin{itemize}
  \item DynamicModelHelper is somewhat vague.
  \item ``scalar data'' is ambiguous -- scalar variables or
    scalar data (potentially from time-indexed variables)
  \item \texttt{get\_data\_at\_time} should be consistent
    between data class and helper class. What if an iterable is
    passed to the helper class method.
  \item ``propagate values'' is vague. This is hard to name
  \item ``shift values'' is vague. ``shift values by time''
    might be better. Needs to imply that time points are changing,
    not data values
  \item Is \texttt{project\_onto\_variables} clear?
\end{itemize}

\section{Feb 3, 2022}

\RP
I've updated the model helper to return data series objects directly.
An open question (probably to pose to John and Bethany) is whether
I should return something like a data series object for scalar
data (which is currently just a dict with CUIDs as keys).

There are enough points for dicussion here that I should focus on cleaning up
what I have, then communicate it to John and Bethany for a design discussion.

\medskip

The simulation script seems to work with new data structures.
I need to:
\begin{itemize}
  \item Remove commented code.
  \item Add helpful comments and docstrings
  \item Commit and push
  \item Send note to Bethany and John.
\end{itemize}

\section{Feb 2, 2022}

\RP
I'm using the model serializer class every time I need to save/load scalar data,
and to facilitate ``cycling'' of the plant and controller models.
I'm also using it to generate time series data for data from the plant.
I'm also using it to generate time series data at sample points from the
controller, then manually extracting the input CUIDs.
Inconveniences I would like to ``abstract away'':
\begin{itemize}
  \item Need to manually ``extend'' time series data.
  \item Need to manually extract subsets of variables.
\end{itemize}
The first is probably the more inconvenient thing, and should be handled by
a class for my dynamic data.

\subsection{Class for dynamic data}
\begin{itemize}
  \item The first thing we need to do is initialize the data structure, which
    right now is just a tuple.
  \item What is the purpose of having a class rather than just a tuple
    (or named tuple)?
    \begin{itemize}
      \item Instantiation (Putting things in the wrong locations of a tuple
	gives no error.)
      \item Convert to json-serializable. I think I have settled on using CUIDs
	as keys. This means my structures are not directly json-serializable.
	I should have a method to convert to json-serializable format.
	And should be able to instantiate from json-serializable format.
      \item Process variables/names to extract a subset of keys.
	Calling ComponentUID repeatedly to construct keys is inconvenient.
	In addition, a user may want to specify keys with a wide variety
	of variable-like objects.
      \item Method for extending. Right now you need to know about the data
	structure to do this. There is also some error-checking we might
	want to do.
    \end{itemize}
  \item An immediate question is whether I should have two different classes
    for scalar and time series data. For now, since my main use case is
    instantiating and extending time series data, I'll just focus on the latter
    functionality. If what I come up with ends up being compatible with
    scalar data, great.
\end{itemize}
Concatenation seems to work. Is the next thing to do manually extract subsets
of variables?
First, how do I like the data class so far?
\begin{itemize}
  \item Instantiation seems fine, but I should really return this object
    from the helper class. If I do this, I should probably have some data
    class for scalar data.
  \item Two potential functionalities are shifting the time list in-place
    and copying the entire object.
    I'll go with the former for now. It is more directly what I want.
  \item I need to be careful when constructing a data series using the time
    points or data from another. I could end up extending data in one series
    while inadvertantly extending it in another.
    I think this is good enough motivation to add a copy method.
\end{itemize}

Extract subsets of variables:
\begin{itemize}
  \item What object to I want to return?
  \item I could just alter the data series in place.
  \item I could return a copy that only has the desired variables.
  \item I could return a list of lists corresponding to the variables
    provided.
  \item All I need to do for now is alter the data series in place, which
    is also the most convenient thing to do.
\end{itemize}

Extracting a subset via \texttt{project\_onto\_variables} seems to work.
How do I feel about the data class?
\begin{itemize}
  \item I should return the data series object directly from
    \texttt{get\_data\_at\_time}
  \item User will have to call \texttt{project\_onto\_variables}
    and \texttt{shift\_time\_points}. I think this is easy enough.
\end{itemize}

This has been successful so far. Next I need to go through the simulation
script and make sure these data structures still work.
Then I need to pull out old code, then I need to update the model helper
to return data series objects directly.

\section{Feb 1, 2022}

\RP
Where was I?
Pipeline NMPC, using some classes for passing data around.
Right now my tests fail because the \texttt{nmpc\_examples} code relies on
workspace \texttt{dynamic\_data}, which changed how strings get generated in
the tracking cost expression function.
I need to fix this by not relying on code from workspace, then I can go through
the simulation and NMPC scripts and remove code using some sort of
\texttt{DynamicModelSerializer} class that uses CUIDs as keys.

I can actually get the tests working just by passing strings through CUID before
sending to the tracking cost expression function.
Now I can copy the \texttt{dynamic\_data} code out of IDAES and update my imports.
This has been done.

\medskip

Is my goal to fix the tracking cost expression function or to remove code using
a model serializer class?
My motivation for switching to CUIDs as keys is so that inconsistencies in
string representations, even within strings from CUIDs, don't cause errors.
This will necessitate a class for the data object, but now I'm getting ahead
of myself.
I should focus on the tracking cost expression function.
Changes to the function itself are minor. Just don't call \texttt{str} on CUIDs.
Should this function process keys in case the user provides strings?
I don't like this, because then we're doing an operation on every key, when
we may only be using a small subset.
Setpoint and weight data structures could be their own objects, however. Then
I extract vectors for user-provided variables. Where user-provided variables
are processed to get the representation used as a key in these data structures.
This seems not bad. There are some tradeoffs here. This is a design question to
pose to John and Bethany.
Note that when a user supplies a list of variables, this induces some sort of
order. It would be nice if the returned object preserves this order (e.g. list
of values).
The ``extract subset'' functionality seems like it should belong to the data
object\ldots

\medskip

Okay, I can use CUIDs as keys in the tracking cost function, and return
data structures using CUIDs as keys from the model helper.

Now:
\begin{enumerate}
  \item Remove all dictionaries using names as keys from the model helper,
    and remove the name generation from \texttt{\_\_init\_\_}.
  \item Go back to the simulation and NMPC scripts, using the model wrapper
    to remove code.
  \item \textbf{Aside:} Should loading values into a model be a function of the
    model wrapper or the serializable data structure. The ambitious answer is
    both. I'm not sure what the \emph{right} answer is.
\end{enumerate}

\section{Jan 24, 2022}

\RP
First thing I need to do is see exactly what KH is doing (and testing) in his
NMPC simulation, so I can recreate it.

To recreate KH's tests, it looks like I need to be able to get plant
and controller data at the end of any particular sample.
In what format should my NMPC routine return ``predicted controller data?''
Probably the same format that it returns plant data. But instead of updating
the controller data with the entire controller model, I should update
with only the first sample.

\medskip

There are differences between my and Kuan-Han's objective functions.
He has a different target for \texttt{Tall[*,Tj]}, and penalizes
\texttt{Tjinb}, which I do not.
I also penalize values at all time points, while he only penalizes
them at sample points.

\medskip

NMPC seems to be working with KH's CSTR. I still need to test that the values
resulting from the solves are reasonable.

\vspace{0.5cm}\hrule\vspace{0.2cm}

\textbf{Aside:} Every time I go about setting up an NMPC script, I am surprised
about how long it takes me. This by itself is motivation enough for an NMPC
toolkit.
What parts take the longest? -- The data management. A small part of which is
passing data back and forth between plant and controller.

\vspace{0.2cm}\hrule\vspace{0.5cm}

Now I have the pipeline models in the \texttt{nmpc\_examples} repo.
I don't, however, have my \texttt{nmpc/} directory with its function
for tracking cost and piecewise constant constraints.
That's fine, I just need to remember to push them next time I have that code
available. Now I can actually start designing some of the code to help
out these simulations.

\medskip

First I'll start with code for transferring data between plant and controller.

\section{Jan 21, 2022}

\RP
Have re-implemented a rolling-horizon simulation of KH's model,
and tested the same values he tests. This works fine. Next is NMPC.

\section{Jan 20, 2022}

\RP
Want to make an NMPC script for Kuan-Han's CSTR example that doesn't use
Caprese. Need to make sure I pass the same tests he has written.
What is Kuan-Han testing in the simulation and NMPC scripts?

NMPC tests:
\begin{itemize}
  \item Tests controller setup.
    \begin{itemize}
      \item  Tests initial conditions of plant
      \item  and all values in controller model
    \end{itemize}
  \item \texttt{test\_solve\_first\_control\_NLP}
    \begin{itemize}
      \item Tests values at time 2.0 in controller model
      \item Tests value of \texttt{Tjinb} at position two in the controller
        dataframe.
      \item Tests values of plant at time 2.0
      \item Tests values in plant dataframe at position two
    \end{itemize}
  \item \texttt{test\_run\_iterations}
    \begin{itemize}
      \item Same tests as above, but runs ten NMPC steps instead of one
    \end{itemize}
\end{itemize}
These tests seem very reasonable. But they do involve some Caprese-specific data
structures, like \texttt{plant\_df} and \texttt{nmpc.controller.mod}.
I should copy the functionality of the tests while scrapping the Caprese
objects, i.e. copy KH's model and re-implement his NMPC problem from scratch
with my own data structures.
Hopefully thsi is not too difficult\ldots

\end{document}
